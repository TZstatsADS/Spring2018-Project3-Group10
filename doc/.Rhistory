sum((fitted_y - train_y)^2)/40
test_x  <- x[fold == i]
test_y  <- y[fold == i]
test_x  <- x[fold == i]
test_y  <- y[fold == i]
train_x <- x[fold != i]
train_y <- y[fold != i]
fit     <- locpoly(train_x,train_y,degree = 1,bandwidth = h[j],gridsize = 1001L)
fitted_y <- rep(NA,10)
for (k in 1:10){
index <- which.min(abs(fit$x - test_x[k]))
fitted_y[k] <- fit$y[index]
}
fitted_y
rcv_1 <- rep(NA,5)
for (i in 1:5) {
test_x  <- x[fold == i]
test_y  <- y[fold == i]
train_x <- x[fold != i]
train_y <- y[fold != i]
fit     <- locpoly(train_x,train_y,degree = 1,bandwidth = h[j],gridsize = 1001L)
fitted_y <- rep(NA,10)
for (k in 1:10){
index <- which.min(abs(fit$x - test_x[k]))
fitted_y[k] <- fit$y[index]
}
rcv_1[i] <- sum((fitted_y - test_y)^2)/10
rcv_1
rcv_1 <- rep(NA,5)
for (i in 1:5) {
test_x  <- x[fold == i]
test_y  <- y[fold == i]
train_x <- x[fold != i]
train_y <- y[fold != i]
fit     <- locpoly(train_x,train_y,degree = 1,bandwidth = h[j],gridsize = 1001L)
fitted_y <- rep(NA,10)
for (k in 1:10){
index <- which.min(abs(fit$x - test_x[k]))
fitted_y[k] <- fit$y[index]
}
rcv_1[i] <- sum((fitted_y - test_y)^2)/10
}
rcv_1
i=2
test_x  <- x[fold == i]
test_y  <- y[fold == i]
train_x <- x[fold != i]
train_y <- y[fold != i]
fit     <- locpoly(train_x,train_y,degree = 1,bandwidth = h[j],gridsize = 1001L)
fitted_y <- rep(NA,10)
for (k in 1:10){
index <- which.min(abs(fit$x - test_x[k]))
fitted_y[k] <- fit$y[index]
}
sum((fitted_y - test_y)^2)/10
fitted_y
k=8
which.min(abs(fit$x - test_x[k]))
test_x[k]
index <- which.min(abs(fit$x - test_x[k]))
index
fitted_y[k] <- fit$y[index]
fitted_y[k]
fit$y[index]
fit$y
fit     <- locpoly(train_x,train_y,degree = 1,bandwidth = h[j],gridsize = 1001L)
fit$y
fit     <- locpoly(train_x,train_y,degree = 1,bandwidth = h[j],gridsize = 401L)
fit$y
train_x
train_y
h[j]
gridsize = 401L
is.na(fit$y)
-(is.na(fit$y))
!(is.na(fit$y))
fit$y[!(is.na(fit$y))]
fit     <- locpoly(train_x,train_y,degree = 1,bandwidth = h[j],gridsize = 1001L)
fit$y[!(is.na(fit$y))]
fit$y   <- fit$y[!(is.na(fit$y))]
fit$x   <- fit$x[!(is.na(fit$y))]
fitted_y <- rep(NA,10)
for (k in 1:10){
index <- which.min(abs(fit$x - test_x[k]))
fitted_y[k] <- fit$y[index]
}
rcv_1[i] <- sum((fitted_y - test_y)^2)/10
rcv_1
rcv[j] <- sum(rcv_1)/5
rcv <- rep(NA,10)
rcv[j] <- sum(rcv_1)/5
rcv[j]
h <- seq(from = 0.05,to = 0.5,by = 0.05)
k <- 5
nums <- rep(1:k, each = length(x)/k)
fold <- sample(nums)
rcv <- rep(NA,10)
for (j in 1:10){
rcv_1 <- rep(NA,5)
for (i in 1:5) {
test_x  <- x[fold == i]
test_y  <- y[fold == i]
train_x <- x[fold != i]
train_y <- y[fold != i]
fit     <- locpoly(train_x,train_y,degree = 1,bandwidth = h[j],gridsize = 1001L)
fit$y   <- fit$y[!(is.na(fit$y))]
fit$x   <- fit$x[!(is.na(fit$y))]
fitted_y <- rep(NA,10)
for (k in 1:10){
index <- which.min(abs(fit$x - test_x[k]))
fitted_y[k] <- fit$y[index]
}
rcv_1[i] <- sum((fitted_y - test_y)^2)/10
}
rcv[j] <- sum(rcv_1)/5
}
rcv
h[which.min(rcv)]
which.min(rcv)
fit_best <- locpoly(x,y,degree = 1,bandwidth = h_best)
h_best <- h[which.min(rcv)]
fit_best <- locpoly(x,y,degree = 1,bandwidth = h_best)
plot(x,y)
lines(fit_best)
install.packages("jpeg")
getwd()
readJPEG("pic.jpg")
library(jpeg)
readJPEG("pic.jpg")
pic <- readJPEG("pic.jpg")
nrow(pic)
help(ksmooth)
#generate data, 2 models with 2 exp dist
gendata <- function(n1, n2){
modeldata <- list()
modeldata$m1 <- rexp(n1, 0.5)
modeldata$m2 <- rexp(n2, 1)
return(modeldata)
}
# simulate to get the expectation
phiR <- function(DataInR){
w <- 0
m1resample <- sample(DataInR$m1, 19, replace = TRUE)
m2resample <- sample(DataInR$m2, 19, replace = TRUE)
x <- m2resample - m1resample
for (i in 1:19){
w = max(w + x[i], 0)
}
return(as.numeric(w > 2))
}
#B >= 2
#First exp
alg4 <- function(OriData, s, B, R){
n <- lapply(OriData, length)
phimat <- matrix(nrow = B, ncol = R)
N1mat <- matrix(nrow = B, ncol = n$m1)
N2mat <- matrix(nrow = B, ncol = n$m2)
for (i in 1:B){
m1bootstrap <- sample(OriData$m1, s$m1, replace = TRUE)
m2bootstrap <- sample(OriData$m2, s$m2, replace = TRUE)
x <- list(m1 = m1bootstrap, m2 = m2bootstrap)
for (j in 1:R){
phimat[i, j] <- phiR(x)
}
#Compute N_{i,j} - s_i / n_i in the Bth Bootstrap (i, j: element j in model i)
for (k in 1:n$m1){
N1mat[i, k] <- sum(x$m1 == OriData$m1[k]) - s$m1 / n$m1
}
for (l in 1:n$m2){
N2mat[i, l] <- sum(x$m2 == OriData$m2[l]) - s$m2 / n$m2
}
}
phib <- apply(phimat, 1, sum) / R
phibarbar<- sum(phib) / B
vec1 <- phib - rep(phibarbar, B)
vec2 <- t(vec1) %*% N1mat
vec3 <- t(vec1) %*% N2mat
vec4 <- t(vec1 ^ 2) %*% N1mat ^ 2
vec5 <- t(vec1 ^ 2) %*% N2mat ^ 2
V <- sum(vec1 ^ 2) / (B - 1)
sigmasqIJ <- (sum(vec2 ^ 2) + sum(vec3 ^ 2)) / (B * (B - 1)) - (sum(vec4) + sum(vec5)) / (B * (B - 1))
list1 <- list(s = V / (B * R), i = sigmasqIJ, phi = phibarbar, v = V)
return(list1)
}
#Second exp
alg4_2 <- function(OriData, s, B, R, Rtilde){
n <- lapply(OriData, length)
phimat <- matrix(nrow = B, ncol = R)
N1mat <- matrix(nrow = B, ncol = n$m1)
N2mat <- matrix(nrow = B, ncol = n$m2)
for (i in 1:B){
m1bootstrap <- sample(OriData$m1, s$m1, replace = TRUE)
m2bootstrap <- sample(OriData$m2, s$m2, replace = TRUE)
x <- list(m1 = m1bootstrap, m2 = m2bootstrap)
for (j in 1:R){
phimat[i, j] <- phiR(x)
}
#Compute N_{i,j} - s_i / n_i in the Bth Bootstrap (i, j: element j in model i)
for (k in 1:n$m1){
N1mat[i, k] <- sum(x$m1 == OriData$m1[k]) - s$m1 / n$m1
}
for (l in 1:n$m2){
N2mat[i, l] <- sum(x$m2 == OriData$m2[l]) - s$m2 / n$m2
}
}
phib <- apply(phimat, 1, sum) / R
phibarbar<- sum(phib) / B
vec1 <- phib - rep(phibarbar, B)
vec2 <- t(vec1) %*% N1mat
vec3 <- t(vec1) %*% N2mat
vec4 <- t(vec1 ^ 2) %*% N1mat ^ 2
vec5 <- t(vec1 ^ 2) %*% N2mat ^ 2
V <- sum(vec1 ^ 2) / (B - 1)
sigmasqIJ <- (sum(vec2 ^ 2) + sum(vec3 ^ 2)) / (B * (B - 1)) - (sum(vec4) + sum(vec5)) / (B * (B - 1))
#fix original data as empirical dist, run \tilde{R} times to get average phitildebar
phitilde <- 0
for (m in 1:Rtilde){
phitilde <- phitilde + phiR(OriData)
}
phitildebar <- phitilde / Rtilde
list1 <- list(s = V / Rtilde , i = sigmasqIJ, phi = phitildebar, v = V)
return(list1)
}
#Third exp
alg4_3 <- function(OriData, s, B, R, Rtilde){
n <- lapply(OriData, length)
phimat <- matrix(nrow = B, ncol = R)
N1mat <- matrix(nrow = B, ncol = n$m1)
N2mat <- matrix(nrow = B, ncol = n$m2)
for (i in 1:B){
m1bootstrap <- sample(OriData$m1, s$m1, replace = TRUE)
m2bootstrap <- sample(OriData$m2, s$m2, replace = TRUE)
x <- list(m1 = m1bootstrap, m2 = m2bootstrap)
for (j in 1:R){
phimat[i, j] <- phiR(x)
}
#Compute N_{i,j} - s_i / n_i in the Bth Bootstrap (i, j: element j in model i)
for (k in 1:n$m1){
N1mat[i, k] <- sum(x$m1 == OriData$m1[k]) - s$m1 / n$m1
}
for (l in 1:n$m2){
N2mat[i, l] <- sum(x$m2 == OriData$m2[l]) - s$m2 / n$m2
}
}
phib <- apply(phimat, 1, sum) / R
phibarbar<- sum(phib) / B
vec1 <- phib - rep(phibarbar, B)
vec2 <- t(vec1) %*% N1mat
vec3 <- t(vec1) %*% N2mat
vec4 <- t(vec1 ^ 2) %*% N1mat ^ 2
vec5 <- t(vec1 ^ 2) %*% N2mat ^ 2
sigmasqIJ <- (sum(vec2 ^ 2) + sum(vec3 ^ 2)) / (B * (B - 1)) - (sum(vec4) + sum(vec5)) / (B * (B - 1))
#fix original data as empirical dist, run \tilde{R} times to get average phitildebar
phitilde <- rep(0, Rtilde)
for (m in 1:Rtilde){
phitilde[m] <- phiR(OriData)
}
phitildebar <- sum(phitilde) / Rtilde
V <- 1 / 2 * sum(vec1 ^ 2) / (B - 1) + var(phitilde) / 2
list1 <- list(s = V / Rtilde , i = sigmasqIJ, phi = phitildebar, v = V)
return(list1)
}
ExpOnAlg4_1 <- function(n1, n2, alpha, s, B, R, Re){
#coverage for those sigma_i >=0, coverage2 for those sigma_i < 0.
#Similar for CIlength and CIlength2; sumV and sumV2; simvar and simvar2
coverage <- 0
coverage2 <- 0
CIlength <- numeric()
CIlength2 <- numeric()
sumV <- 0
sumV2 <- 0
inputvar <- numeric()
simvar <- 0
simvar2 <- 0
t <- 0
#main body
for (times in 1:Re){
x <- gendata(n1, n2)
list1 <- alg4(x, s, B, R)
if (list1$i >= 0){
sigma <- list1$s + list1$i
coverage <- coverage + (abs(0.182 - list1$phi) < (qnorm(1 - alpha / 2) * sqrt(sigma)))
CIlength[times] <- 2 * qnorm(1 - alpha / 2) * sqrt(sigma)
inputvar[times] <- list1$i
simvar <- simvar + list1$s
sumV <- sumV + list1$v
t <- t + 1
}
else{
sigma <- list1$s
coverage2 <- coverage2 + (abs(0.182 - list1$phi) < (qnorm(1 - alpha / 2) * sqrt(sigma)))
CIlength2[times] <- 2 * qnorm(1 - alpha / 2) * sqrt(sigma)
simvar2 <- simvar2 + list1$s
sumV2 <- sumV2 + list1$v
}
}
#out1: remove those sigma_i < 0
sumofsigmaisq1 <- sum(inputvar, na.rm = TRUE)
out1 <- c(t, coverage / t, mean(CIlength, na.rm = TRUE), sd(CIlength, na.rm = TRUE), sqrt(sumofsigmaisq1 / simvar), sumofsigmaisq1 / t, sd(inputvar, na.rm = TRUE), sumofsigmaisq1 / sumV)
#out2: substitue those sigma_i < 0 with 0
totalCIlength <- c(as.numeric(na.omit(CIlength)), as.numeric(na.omit(CIlength2)))
inputvar[is.na(inputvar)] <- 0
out2 <- c((coverage + coverage2) / Re, mean(totalCIlength), sd(totalCIlength), sqrt(sumofsigmaisq1 / (simvar + simvar2)), sumofsigmaisq1 / Re, sd(inputvar), sumofsigmaisq1 / (sumV + sumV2))
out <- c(out1, NA, out2)
return(out)
}
#outcome
s1 = list(m1 = 30, m2 = 30)
ExpOnAlg4_2 <- function(n1, n2, alpha, s, B, R, Rtilde, Re){
#coverage for those sigma_i >=0, coverage2 for those sigma_i < 0.
#Similar for CIlength and CIlength2; sumV and sumV2; simvar and simvar2
coverage <- 0
coverage2 <- 0
CIlength <- numeric()
CIlength2 <- numeric()
sumV <- 0
sumV2 <- 0
inputvar <- numeric()
simvar <- 0
simvar2 <- 0
t <- 0
#main body
for (times in 1:Re){
x <- gendata(n1, n2)
list1 <- alg4_2(x, s, B, R, Rtilde)
if (list1$i >= 0){
sigma <- list1$s + list1$i
coverage <- coverage + (abs(0.182 - list1$phi) < (qnorm(1 - alpha / 2) * sqrt(sigma)))
CIlength[times] <- 2 * qnorm(1 - alpha / 2) * sqrt(sigma)
inputvar[times] <- list1$i
simvar <- simvar + list1$s
sumV <- sumV + list1$v
t <- t + 1
}
else{
sigma <- list1$s
coverage2 <- coverage2 + (abs(0.182 - list1$phi) < (qnorm(1 - alpha / 2) * sqrt(sigma)))
CIlength2[times] <- 2 * qnorm(1 - alpha / 2) * sqrt(sigma)
simvar2 <- simvar2 + list1$s
sumV2 <- sumV2 + list1$v
}
}
#out1: remove those sigma_i < 0
sumofsigmaisq1 <- sum(inputvar, na.rm = TRUE)
out1 <- c(t, coverage / t, mean(CIlength, na.rm = TRUE), sd(CIlength, na.rm = TRUE), sqrt(sumofsigmaisq1 / simvar), sumofsigmaisq1 / t, sd(inputvar, na.rm = TRUE), sumofsigmaisq1 / sumV)
#out2: substitue those sigma_i < 0 with 0
totalCIlength <- c(as.numeric(na.omit(CIlength)), as.numeric(na.omit(CIlength2)))
inputvar[is.na(inputvar)] <- 0
out2 <- c((coverage + coverage2) / Re, mean(totalCIlength), sd(totalCIlength), sqrt(sumofsigmaisq1 / (simvar + simvar2)), sumofsigmaisq1 / Re, sd(inputvar), sumofsigmaisq1 / (sumV + sumV2))
out <- c(out1, NA, out2)
return(out)
}
ExpOnAlg4_3 <- function(n1, n2, alpha, s, B, R, Rtilde, Re){
#coverage for those sigma_i >=0, coverage2 for those sigma_i < 0.
#Similar for CIlength and CIlength2; sumV and sumV2; simvar and simvar2
coverage <- 0
coverage2 <- 0
CIlength <- numeric()
CIlength2 <- numeric()
sumV <- 0
sumV2 <- 0
inputvar <- numeric()
simvar <- 0
simvar2 <- 0
t <- 0
#main body
for (times in 1:Re){
x <- gendata(n1, n2)
list1 <- alg4_3(x, s, B, R, Rtilde)
if (list1$i >= 0){
sigma <- list1$s + list1$i
coverage <- coverage + (abs(0.182 - list1$phi) < (qnorm(1 - alpha / 2) * sqrt(sigma)))
CIlength[times] <- 2 * qnorm(1 - alpha / 2) * sqrt(sigma)
inputvar[times] <- list1$i
simvar <- simvar + list1$s
sumV <- sumV + list1$v
t <- t + 1
}
else{
sigma <- list1$s
coverage2 <- coverage2 + (abs(0.182 - list1$phi) < (qnorm(1 - alpha / 2) * sqrt(sigma)))
CIlength2[times] <- 2 * qnorm(1 - alpha / 2) * sqrt(sigma)
simvar2 <- simvar2 + list1$s
sumV2 <- sumV2 + list1$v
}
}
#out1: remove those sigma_i < 0
sumofsigmaisq1 <- sum(inputvar, na.rm = TRUE)
out1 <- c(t, coverage / t, mean(CIlength, na.rm = TRUE), sd(CIlength, na.rm = TRUE), sqrt(sumofsigmaisq1 / simvar), sumofsigmaisq1 / t, sd(inputvar, na.rm = TRUE), sumofsigmaisq1 / sumV)
#out2: substitue those sigma_i < 0 with 0
totalCIlength <- c(as.numeric(na.omit(CIlength)), as.numeric(na.omit(CIlength2)))
inputvar[is.na(inputvar)] <- 0
out2 <- c((coverage + coverage2) / Re, mean(totalCIlength), sd(totalCIlength), sqrt(sumofsigmaisq1 / (simvar + simvar2)), sumofsigmaisq1 / Re, sd(inputvar), sumofsigmaisq1 / (sumV + sumV2))
out <- c(out1, NA, out2)
return(out)
}
table3 <- matrix(nrow = 5, ncol = 16)
colnames(table3) <- c("t", "Coverage", "mean CI length", "std. CI Length", "sqrt(sigmaIsq/sigmaSsq)", "mean sigmaIsq", "std sigmaIsq", "sigmaIsq/V", "seperate col", "Coverage", "mean CI length", "std. CI Length", "sqrt(sigmaIsq/sigmaSsq)", "mean sigmaIsq", "std sigmaIsq", "sigmaIsq/V")
table3[1,] <- ExpOnAlg4_2(60, 30, 0.05, s1, 1000, 1, 100, 1000)
table3[2,] <- ExpOnAlg4_2(200, 100, 0.05, s1, 1000, 1, 100, 1000)
table3[3,] <- ExpOnAlg4_2(600, 300, 0.05, s1, 2000, 1, 100, 1000)
write.csv(table3, "table3.csv")
## Budget N varies, to choose the optimal B, R, theta as shown in P12 and P13, Rtilde = 100
table4 <- matrix(nrow = 5, ncol = 19)
colnames(table4) <- c("t", "Coverage", "mean CI length", "std. CI Length", "sqrt(sigmaIsq/sigmaSsq)", "mean sigmaIsq", "std sigmaIsq", "sigmaIsq/V", "seperate col", "Coverage", "mean CI length", "std. CI Length", "sqrt(sigmaIsq/sigmaSsq)", "mean sigmaIsq", "std sigmaIsq", "sigmaIsq/V", "theta", "s1", "s2")
table4[1,] <- thetaselection2(60, 30, 0.05, 1000, 1, 100, 1000)
table4[2,] <- thetaselection2(200, 100, 0.05, 1000, 1, 100, 1000)
table4[3,] <- thetaselection2(600, 300, 0.05, 2000, 1, 100, 1000)
write.csv(table4, "table4.csv")
## To reproduce Table1-like on P45 Rtilde = 200
## B = {1000, 1000, 2000, 4000, 6000}, R = 1, s = (30, 30)
table5 <- matrix(nrow = 5, ncol = 16)
colnames(table5) <- c("t", "Coverage", "mean CI length", "std. CI Length", "sqrt(sigmaIsq/sigmaSsq)", "mean sigmaIsq", "std sigmaIsq", "sigmaIsq/V", "seperate col", "Coverage", "mean CI length", "std. CI Length", "sqrt(sigmaIsq/sigmaSsq)", "mean sigmaIsq", "std sigmaIsq", "sigmaIsq/V")
table5[1,] <- ExpOnAlg4_2(60, 30, 0.05, s1, 1000, 1, 200, 1000)
table5[2,] <- ExpOnAlg4_2(200, 100, 0.05, s1, 1000, 1, 200, 1000)
## Budget N varies, to choose the optimal B, R, theta as shown in P12 and P13, Rtilde = 100
thetaselection2 <- function(n1, n2, alpha, B, R, Rtilde, Re){
n = (n1 + n2) / 2
theta = min(sqrt(B), n ^ (3 / 4)) * n ^ (-5 / 4)
s1 <- ceiling(n1 * theta)
s2 <- ceiling(n2 * theta)
s <- list(m1 = s1, m2 = s2)
out <- c(ExpOnAlg4_2(n1, n2, alpha, s, B, R, Rtilde, Re), theta, s1, s2)
return(out)
}
## Budget N varies, to choose the optimal B, R, theta as shown in P12 and P13, Rtilde = 100
thetaselection3 <- function(n1, n2, alpha, B, R, Rtilde, Re){
n = (n1 + n2) / 2
theta = min(sqrt(B), n ^ (3 / 4)) * n ^ (-5 / 4)
s1 <- ceiling(n1 * theta)
s2 <- ceiling(n2 * theta)
s <- list(m1 = s1, m2 = s2)
out <- c(ExpOnAlg4_3(n1, n2, alpha, s, B, R, Rtilde, Re), theta, s1, s2)
return(out)
}
table4 <- matrix(nrow = 5, ncol = 19)
colnames(table4) <- c("t", "Coverage", "mean CI length", "std. CI Length", "sqrt(sigmaIsq/sigmaSsq)", "mean sigmaIsq", "std sigmaIsq", "sigmaIsq/V", "seperate col", "Coverage", "mean CI length", "std. CI Length", "sqrt(sigmaIsq/sigmaSsq)", "mean sigmaIsq", "std sigmaIsq", "sigmaIsq/V", "theta", "s1", "s2")
table4[1,] <- thetaselection2(60, 30, 0.05, 1000, 1, 100, 1000)
table4[2,] <- thetaselection2(200, 100, 0.05, 1000, 1, 100, 1000)
table4[3,] <- thetaselection2(600, 300, 0.05, 2000, 1, 100, 1000)
write.csv(table4, "table4.csv")
## To reproduce Table1-like on P45 Rtilde = 200
## B = {1000, 1000, 2000, 4000, 6000}, R = 1, s = (30, 30)
table5 <- matrix(nrow = 5, ncol = 16)
colnames(table5) <- c("t", "Coverage", "mean CI length", "std. CI Length", "sqrt(sigmaIsq/sigmaSsq)", "mean sigmaIsq", "std sigmaIsq", "sigmaIsq/V", "seperate col", "Coverage", "mean CI length", "std. CI Length", "sqrt(sigmaIsq/sigmaSsq)", "mean sigmaIsq", "std sigmaIsq", "sigmaIsq/V")
table5[1,] <- ExpOnAlg4_2(60, 30, 0.05, s1, 1000, 1, 200, 1000)
table5[2,] <- ExpOnAlg4_2(200, 100, 0.05, s1, 1000, 1, 200, 1000)
table5[3,] <- ExpOnAlg4_2(600, 300, 0.05, s1, 2000, 1, 200, 1000)
write.csv(table5, "table5.csv")
## Budget N varies, to choose the optimal B, R, theta as shown in P12 and P13, Rtilde = 100
table6 <- matrix(nrow = 5, ncol = 19)
colnames(table6) <- c("t", "Coverage", "mean CI length", "std. CI Length", "sqrt(sigmaIsq/sigmaSsq)", "mean sigmaIsq", "std sigmaIsq", "sigmaIsq/V", "seperate col", "Coverage", "mean CI length", "std. CI Length", "sqrt(sigmaIsq/sigmaSsq)", "mean sigmaIsq", "std sigmaIsq", "sigmaIsq/V", "theta", "s1", "s2")
table6[1,] <- thetaselection2(60, 30, 0.05, 1000, 1, 200, 1000)
table6[2,] <- thetaselection2(200, 100, 0.05, 1000, 1, 200, 1000)
table6[3,] <- thetaselection2(600, 300, 0.05, 2000, 1, 200, 1000)
write.csv(table6, "table6.csv")
table7 <- matrix(nrow = 5, ncol = 16)
colnames(table7) <- c("t", "Coverage", "mean CI length", "std. CI Length", "sqrt(sigmaIsq/sigmaSsq)", "mean sigmaIsq", "std sigmaIsq", "sigmaIsq/V", "seperate col", "Coverage", "mean CI length", "std. CI Length", "sqrt(sigmaIsq/sigmaSsq)", "mean sigmaIsq", "std sigmaIsq", "sigmaIsq/V")
table7[1,] <- ExpOnAlg4_3(60, 30, 0.05, s1, 1000, 1, 100, 1000)
table7[2,] <- ExpOnAlg4_3(200, 100, 0.05, s1, 1000, 1, 100, 1000)
table7[3,] <- ExpOnAlg4_3(600, 300, 0.05, s1, 2000, 1, 100, 1000)
write.csv(table7, "table7.csv")
## Budget N varies, to choose the optimal B, R, theta as shown in P12 and P13, Rtilde = 100
table8 <- matrix(nrow = 5, ncol = 19)
colnames(table8) <- c("t", "Coverage", "mean CI length", "std. CI Length", "sqrt(sigmaIsq/sigmaSsq)", "mean sigmaIsq", "std sigmaIsq", "sigmaIsq/V", "seperate col", "Coverage", "mean CI length", "std. CI Length", "sqrt(sigmaIsq/sigmaSsq)", "mean sigmaIsq", "std sigmaIsq", "sigmaIsq/V", "theta", "s1", "s2")
table8[1,] <- thetaselection3(60, 30, 0.05, 1000, 1, 100, 1000)
table8[2,] <- thetaselection3(200, 100, 0.05, 1000, 1, 100, 1000)
table8[3,] <- thetaselection3(600, 300, 0.05, 2000, 1, 100, 1000)
#
library(randomForest)
library(caret)
library(e1071)
setwd("~/GitHub/Spring2018-Project3-spring2018-project3-group10/doc")
getwd()
features <- read.csv('../data/SIFT_train')
features <- read.csv('../data/SIFT_train.csv')
features <- read.csv('../data/SIFT_train.csv',header = F)
features <- features[,-1]
labels_set <- read.csv('../data/label_train.csv')
labels <- labels_set[,3]
dataset <- cbind(labels,features)
dim(dataset)
mtry.range=c(5:15)
ntree.range=c(1000, 1500, 2000, 2500)
cv.error <- matrix(NA,ncol = 4,nrow = 11)
rownames(cv.error) <- mtry.range
colnames(cv.error) <- ntree.range
for (i in 1:11){
for (j in 1:4){
error <- rep(NA,5)
for (k in 1:5){
n <- length(labels)
n.fold <- floor(n/5)
s <- sample(rep(1:5, each = n.fold))
train <- dataset[s != k,]
test <- dataset[s == k,]
train_labels <- train[,1]
train_features <- train[,2:ncol(train)]
test_labels <- test[,1]
test_features <- test[,2:ncol(test)]
fit <- randomForest(as.factor(train_labels) ~ .,
data = train_features, mtry = mtry.range[i],
importance=TRUE,
ntree=ntree.range[j])
Prediction <- predict(fit, test_features)
Accuracy <- sum(Prediction == test_labels)/length(test_labels)
error[k] <- 1 - Accuracy
}
print(error)
cv.error[i,j] <- mean(error)
}
}
