baseline.model = list(fit = baseline.result[[1]])
baseline.test.pre = test_gbm(baseline.model, sift_test)
View(sift_test)
baseline.test.pre = test_gbm(baseline.model, sift_test)
View(label_test)
baseline.test.pre = test(baseline.model, sift_test)
baseline.test.pre = predict(baseline.model$fit, sift_test)
baseline.model
baseline.result[[1]]
baseline.test.pre = predict(baseline.result[[1]], sift_test)
load("../output/gbm.fit.model.Rdata")
baseline.test.pre = predict(gbm.fit, sift_test)
sift_test = read.csv('../data/sift_test.csv', header = T)
View(sift_test)
sift_test$Image_Number = c(1:3000)
load("../output/baseline.result.Rdata")
baseline.model = list(fit = baseline.result[[1]])
baseline.test.pre = predict(baseline.result[[1]], sift_test)
df = train_test_split('lbp')
test_lr_prediction = test(lr, df_test)
test_lr_prediction
write.csv(test_lr_prediction,"../output/cnn_test_prediction.csv")
load("../output/gbm.fit.LBP.Rdata")
test_lr_prediction = test_gbm(gbm, df_test)
test_lr_prediction
write.csv(test_lr_prediction,"../output/lr_test_prediction.csv")
write.csv(test_gbm_prediction,"../output/gbm_test_prediction.csv")
test_gbm_prediction = test_gbm(gbm, df_test)
write.csv(test_gbm_prediction,"../output/gbm_test_prediction.csv")
load("../output/baseline.result.Rdata")
baseline.model = list(fit = baseline.result[[1]])
baseline.test.pre = predict(baseline.model, sift_test)
label_test = data.frame(X = c(1:3000), 'GBM', 'SVM', 'Random Forest', 'Logistic Regression', 'Neural Networks')
View(label_test)
test_gbm
packages.used=c("caret","gbm", "e1071", "DMwR", "nnet", "randomForest","OpenImageR","DT", "caTools", "EBImage", "mxnet", "pbapply", "ggthemes")
# check packages that need to be installed.
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
# install additional packages
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE)
}
library(caret)
library(gbm)
library(e1071)
library(DMwR)
library(randomForest)
library(nnet)
library(OpenImageR)
library(DT)
library(caTools)
library(EBImage)
library(mxnet)
library(pbapply)
library(ggthemes)
source("../lib/train.R")
source("../lib/test.R")
source("../lib/train_test_split.R")
load("../output/baseline.result.Rdata")
baseline.time = baseline.result[[4]]
baseline.time
baseline.accuracy = 1 - baseline.result[[3]]
print(paste0("The accuracy rate of baseline model is ", baseline.accuracy))
# Classifications                   Accuracy Rate
# Sift + GBM                              ~73%
# Sift + Logistic Regression              ~71%
# Sift + Random Forest                    ~73%
# Sift + SVM                              ~33%
load("../output/lbp.result.Rdata")
lbp.result
load("../output/hog.para.accuracy.Rdata")
hog.para.accuracy
df = train_test_split("hog510")
HoG_train = df$df_train
HoG_test = df$df_test
load("../output/hog.result.Rdata")
hog.result
load("../output/lbp.result.Rdata")
load("../output/hog.result.Rdata")
load("../output/baseline.result.Rdata")
lbp.result$Feature<-rep("LBP",ncol(lbp.result))
hog.result$Feature<-rep("HoG",ncol(hog.result))
comp<-rbind(lbp.result,hog.result)
comp<-comp[,c(1,5,2,3,4)]
comp[,1] = as.character(comp[,1])
# round the accuracy rate and running time
comp$Test_accuracy <- round(comp$Test_accuracy,3)
comp$Running_Time <- round(comp$Running_Time,3)
par(mfrow=c(1,2))
ggplot(data=comp, aes(x=Model,y=Test_accuracy,color=Feature,fill=Feature)) +
geom_bar(stat="identity", position=position_dodge(), width = 0.4)+
geom_text(aes(label=Test_accuracy),color="Black",hjust=-0.2, position = position_dodge(0.5))+
theme_bw()+
scale_y_continuous(limits = c(0,1))+
#theme_solarized(light = T)+
coord_flip()
ggplot(data=comp, aes(x=Model,y=Running_Time,color=Feature,fill=Feature)) +
geom_bar(stat = "identity", position = position_dodge(), width = 0.4)+
geom_text(aes(label=Running_Time),color="Black",hjust=-0.1, position = position_dodge(0.5))+
theme_bw()+
scale_y_continuous(limits = c(0,150))+
ylab("Running Time(secs)")+
#theme_solarized(light = T)+
coord_flip()
comp<-rbind(comp,c("GBM","Sift",1-baseline.result[[2]],1-baseline.result[[3]],baseline.result[[4]]))
comp<-rbind(comp,c("CNN","CNN",0.963, 0.842,1924))
datatable(comp)
df_test = read.csv("../output/lbp_test.csv", header = F)
sift_test = read.csv('../data/sift_test.csv', header = T)
load("../output/lr.fit.LBP.Rdata")
load("../output/rf.fit.LBP.Rdata")
load("../output/svm.fit.LBP.Rdata")
load("../output/gbm.fit.LBP.Rdata")
load("../output/baseline.result.Rdata")
baseline.model = list(fit = baseline.result[[1]])
baseline.test.pre = predict(baseline.model, sift_test)
test_lr = test(lr, df_test)
test_rf = test(rf, df_test)
test_svm = test(svm, df_test)
test_gbm = test_gbm(gbm, df_test)
baseline.result
label_test = read.csv("../output/cnn_test_prediction.csv", header = T)
label_test = data.frame(X = c(1:3000), 'GBM' = test_gbm, 'SVM', 'Random Forest', 'Logistic Regression', 'Neural Networks')
View(label_test)
label_test = read.csv("../data/test_label", header = T)
label_test = read.csv("../data/label_test", header = T)
label_test = read.csv("../data/label_test.csv", header = T)
View(label_test)
test_cnn = read.csv('../output/cnn_test_prediction.csv')
label_test = data.frame(X = c(1:3000), 'GBM' = test_gbm, 'SVM' = test_svm, 'Random Forest' = test_rf 'Logistic Regression' = test_lr, 'Neural Networks' = test_cnn[,2])
test_cnn[,2]
label_test = data.frame(X = c(1:3000), 'GBM' = test_gbm, 'SVM' = test_svm, 'Random Forest' = test_rf 'Logistic Regression' = test_lr)
test_lr = test(lr, df_test)
test_rf = test(rf, df_test)
label_test = data.frame(X = c(1:3000), 'GBM' = test_gbm, 'SVM' = test_svm, 'Random Forest' = test_rf 'Logistic Regression' = test_lr,, 'Neural Networks' = test_cnn[,2])
test_gbm
test_cnn[,2]
label_test = data.frame(X = c(1:3000), 'GBM' = test_gbm, 'SVM' = test_svm, 'Random Forest' = test_rf 'Logistic Regression' = test_lr,'Neural Networks' = test_cnn[,2])
label_test = data.frame(X = c(1:3000), 'GBM' = test_gbm, 'SVM' = test_svm, 'Random Forest' = test_rf 'Logistic Regression' = test_lr,'Neural Networks' = as.numeric(test_cnn[,2]))
label_test = data.frame(X = c(1:3000), 'GBM' = test_gbm, 'SVM' = test_svm, 'Random Forest' = test_rf 'Logistic Regression' = test_lr,'Neural Networks' = as.vector(test_cnn[,2]))
label_test = data.frame(X = c(1:3000), 'GBM' = test_gbm, 'SVM' = test_svm, 'Random Forest' = test_rf 'Logistic Regression' = test_lr)
label_test = data.frame(X = c(1:3000), 'GBM' = test_gbm, 'SVM' = test_svm, 'Random Forest' = test_rf, 'Logistic Regression' = test_lr, 'Neural Networks' = as.vector(test_cnn[,2]))
View(label_test)
write.csv(label_test_baseline, 'label_test_baseline.csv',row.names = F)
label_test_baseline = data.frame(X = c(1:3000), 'baseline' = test_gbm)
write.csv(label_test_baseline, 'label_test_baseline.csv',row.names = F)
label_test = data.frame(X = c(1:3000), 'GBM' = test_gbm, 'SVM' = test_svm, 'Random Forest' = test_rf, 'Logistic Regression' = test_lr, 'Neural Networks' = as.vector(test_cnn[,2]))
View(label_test)
label_test_all = data.frame(X = c(1:3000), 'GBM' = test_gbm, 'SVM' = test_svm, 'Random Forest' = test_rf, 'Logistic Regression' = test_lr, 'Neural Networks' = as.vector(test_cnn[,2]))
write.csv(label_test_all, 'label_test_baseline.csv',row.names = F)
write.csv(label_test_baseline, 'label_test_baseline.csv',row.names = F)
write.csv(label_test_all, 'label_test_all.csv',row.names = F)
mv_df = read.csv('../output/all_train_prediction.csv', header = T)
View(mv_df)
mv_label = mv_df$combo_train_prediction
df = train_test_split('lbp')
mean(mv_label == df_test)
load("../output/svm.fit.LBP.Rdata")
svm
df = train_test_split('lbp')
svm_result = test(svm, df$df_test)
svm_result
svm_train_prediction = test(svm, df$df_test)
write.csv(svm_train_prediction, '../output/svm_train_prediction.csv', row.names = F)
cnn_train_prediction = read.csv("../output/cnn_train_prediction.csv")$x
setwd("~/Documents/GitHub/Fall2017-project3-fall2017-project3-grp4/doc")
cnn_train_prediction = read.csv("../output/cnn_train_prediction.csv")$x
cnn_train_prediction = read.csv("../output/svm_train_prediction.csv")$x
lr_train_prediction = read.csv("../output/lr_train_prediction.csv")$x
gbm_train_prediction = read.csv("../output/gbm_train_prediction.csv")$x
all_train=data.frame(cnn_train_prediction,lr_train_prediction,gbm_train_prediction)
for (i in 1:3000){
if (all_train[i,1]==all_train[i,2]){
all_train[i,4]=all_train[i,1]
} else if (all_train[i,1]==all_train[i,3]){
all_train[i,4]=all_train[i,1]
} else if (all_train[i,2]==all_train[i,3]){
all_train[i,4]=all_train[i,3]
} else{
all_train[i,4]=all_train[i,2]
}
}
df=train_test_split('lbp')
mean(all_train$V4 == df_test)
View(all_train)
df_test
View(df_test)
a = df$df_train
b = df$df_test
df = train_test_split('lbp')
svm_pre = test(svm,df$df_test)
svm_pre
gbm_pre = test(gbm,df$df_test)
gbm_pre = test.gbm(gbm,df$df_test)
source("../lib/test.R")
gbm_pre = test_gbm(gbm,df$df_test)
all_train=data.frame(svm_pre,lr_pre,gbm_pre)
lr_pre = test(lr,df$df_test)
all_train=data.frame(svm_pre,lr_pre,gbm_pre)
for (i in 1:600){
if (all_train[i,1]==all_train[i,2]){
all_train[i,4]=all_train[i,1]
} else if (all_train[i,1]==all_train[i,3]){
all_train[i,4]=all_train[i,1]
} else if (all_train[i,2]==all_train[i,3]){
all_train[i,4]=all_train[i,3]
} else{
all_train[i,4]=all_train[i,2]
}
}
mean(all_train$V4 == df_test)
mean(all_train$V4 == df$df_test)
all_train$V4
mean(all_train$V4 == df$df_test)
df$df_test
b = df$df_test
mean(all_train$V4 == df$df_test$Label)
load("../output/lbp.result.Rdata")
load("../output/hog.result.Rdata")
load("../output/baseline.result.Rdata")
lbp.result$Feature<-rep("LBP",ncol(lbp.result))
hog.result$Feature<-rep("HoG",ncol(hog.result))
comp<-rbind(lbp.result,hog.result)
View(comp)
print(paste0("The test accuracy of the majority vote model is ", mean(all_train$V4 == df$df_test$Label)))
colnames(comp)
test_svm
all_train=data.frame(test_svm,test_lr,test_gbm)
all_train=data.frame(test_svm,test_lr,test_gbm)
test_svm
test_gbm_1 = test_gbm(gbm, df_test)
test_gbm_1
all_train=data.frame(test_svm,test_lr,test_gbm_1)
for (i in 1:3000){
if (all_train[i,1]==all_train[i,2]){
all_train[i,4]=all_train[i,1]
} else if (all_train[i,1]==all_train[i,3]){
all_train[i,4]=all_train[i,1]
} else if (all_train[i,2]==all_train[i,3]){
all_train[i,4]=all_train[i,3]
} else{
all_train[i,4]=all_train[i,2]
}
}
packages.used=c("caret","gbm", "e1071", "DMwR", "nnet", "randomForest","OpenImageR","DT", "caTools", "EBImage", "mxnet", "pbapply", "ggthemes")
# check packages that need to be installed.
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
# install additional packages
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE)
}
library(caret)
library(gbm)
library(e1071)
library(DMwR)
library(randomForest)
library(nnet)
library(OpenImageR)
library(DT)
library(caTools)
library(EBImage)
library(mxnet)
library(pbapply)
library(ggthemes)
source("../lib/train.R")
source("../lib/test.R")
source("../lib/train_test_split.R")
load("../output/baseline.result.Rdata")
baseline.time = baseline.result[[4]]
baseline.time
baseline.accuracy = 1 - baseline.result[[3]]
print(paste0("The accuracy rate of baseline model is ", baseline.accuracy))
# Classifications                   Accuracy Rate
# Sift + GBM                              ~73%
# Sift + Logistic Regression              ~71%
# Sift + Random Forest                    ~73%
# Sift + SVM                              ~33%
load("../output/lbp.result.Rdata")
lbp.result
load("../output/hog.para.accuracy.Rdata")
hog.para.accuracy
df = train_test_split("hog510")
HoG_train = df$df_train
HoG_test = df$df_test
load("../output/hog.result.Rdata")
hog.result
load("../output/lr.fit.LBP.Rdata")
load("../output/svm.fit.LBP.Rdata")
load("../output/gbm.fit.LBP.Rdata")
# Here is the code we use to create majority vote matrix
df = train_test_split('lbp')
svm_pre = test(svm,df$df_test)
lr_pre = test(lr,df$df_test)
gbm_pre = test_gbm(gbm,df$df_test)
all_train=data.frame(svm_pre,lr_pre,gbm_pre)
for (i in 1:600){
if (all_train[i,1]==all_train[i,2]){
all_train[i,4]=all_train[i,1]
} else if (all_train[i,1]==all_train[i,3]){
all_train[i,4]=all_train[i,1]
} else if (all_train[i,2]==all_train[i,3]){
all_train[i,4]=all_train[i,3]
} else{
all_train[i,4]=all_train[i,2]
}
}
print(paste0("The test accuracy of the majority vote model is ", mean(all_train$V4 == df$df_test$Label)))
load("../output/lbp.result.Rdata")
load("../output/hog.result.Rdata")
load("../output/baseline.result.Rdata")
lbp.result$Feature<-rep("LBP",ncol(lbp.result))
hog.result$Feature<-rep("HoG",ncol(hog.result))
comp<-rbind(lbp.result,hog.result)
comp<-comp[,c(1,5,2,3,4)]
comp[,1] = as.character(comp[,1])
# round the accuracy rate and running time
comp$Test_accuracy <- round(comp$Test_accuracy,3)
comp$Running_Time <- round(comp$Running_Time,3)
par(mfrow=c(1,2))
ggplot(data=comp, aes(x=Model,y=Test_accuracy,color=Feature,fill=Feature)) +
geom_bar(stat="identity", position=position_dodge(), width = 0.4)+
geom_text(aes(label=Test_accuracy),color="Black",hjust=-0.2, position = position_dodge(0.5))+
theme_bw()+
scale_y_continuous(limits = c(0,1))+
#theme_solarized(light = T)+
coord_flip()
ggplot(data=comp, aes(x=Model,y=Running_Time,color=Feature,fill=Feature)) +
geom_bar(stat = "identity", position = position_dodge(), width = 0.4)+
geom_text(aes(label=Running_Time),color="Black",hjust=-0.1, position = position_dodge(0.5))+
theme_bw()+
scale_y_continuous(limits = c(0,150))+
ylab("Running Time(secs)")+
#theme_solarized(light = T)+
coord_flip()
comp<-rbind(comp,c("GBM","Sift",1-baseline.result[[2]],1-baseline.result[[3]],baseline.result[[4]]))
comp<-rbind(comp,c("CNN","CNN",0.963, 0.842,1924))
datatable(comp)
comp
df_test = read.csv("../output/lbp_test.csv", header = F)
test_cnn = read.csv('../output/cnn_test_prediction.csv')
#Get the label of the baseline model's prediction
label_test_baseline = data.frame(X = c(1:3000), 'baseline' = test_gbm)
label_test_baseline = data.frame(X = c(1:3000), 'baseline' = test_gbm_1)
test_gbm_1
sift_test = read.csv('../data/sift_test.csv', header = T)
load("../output/lr.fit.LBP.Rdata")
load("../output/rf.fit.LBP.Rdata")
load("../output/svm.fit.LBP.Rdata")
load("../output/gbm.fit.LBP.Rdata")
load("../output/baseline.result.Rdata")
baseline.model = list(fit = baseline.result[[1]])
baseline.test.pre = predict(baseline.model, sift_test)
test_lr = test(lr, df_test)
test_rf = test(rf, df_test)
test_svm = test(svm, df_test)
test_gbm_1 = test_gbm(gbm, df_test)
test_cnn = read.csv('../output/cnn_test_prediction.csv')
#Get the label of the baseline model's prediction
label_test_baseline = data.frame(X = c(1:3000), 'baseline' = test_gbm_1)
write.csv(label_test_baseline, 'label_test_baseline.csv',row.names = F)
#Get the label of other classification model's prediction
all_train=data.frame(test_svm,test_lr,test_gbm_1)
for (i in 1:3000){
if (all_train[i,1]==all_train[i,2]){
all_train[i,4]=all_train[i,1]
} else if (all_train[i,1]==all_train[i,3]){
all_train[i,4]=all_train[i,1]
} else if (all_train[i,2]==all_train[i,3]){
all_train[i,4]=all_train[i,3]
} else{
all_train[i,4]=all_train[i,2]
}
}
label_test_all = data.frame(X = c(1:3000), 'GBM' = test_gbm_1, 'SVM' = test_svm, 'Random Forest' = test_rf, 'Logistic Regression' = test_lr, 'Neural Networks' = as.vector(test_cnn[,2]), 'majority_vote' = all_train$V4)
write.csv(label_test_all, 'label_test_all.csv',row.names = F)
label_test_all = data.frame(X = c(1:3000), 'GBM' = test_gbm_1, 'SVM' = test_svm, 'Random Forest' = test_rf, 'Logistic Regression' = test_lr, 'Neural Networks' = as.vector(test_cnn[,2]), 'majority_vote' = all_train$V4)
View(label_test_all)
baseline.result = train_gbm(Sift_train)
source("../lib/train_test_split.R")
source("../lib/train1.R")
source("../lib/test1.R")
getwd()
setwd("~/Spring2018-Project3-Group10")
setwd("~/Spring2018-Project3-Group10/doc")
setwd("~/Spring2018-Project3-Group10/doc")
source("../lib/train1.R")
source("../lib/test1.R")
source("../lib/train_test_split.R")
df = train_test_split("sift")
Sift_train = df_train
Sift_test = df_test
Sift_train = df$df_train
Sift_test = df$df_test
Sift_train = df$df_train[,-1]
Sift_test = df$df_test[,-1]
colnames(Sift_test)
source("../lib/train1.R")
source("../lib/test1.R")
baseline.result = train_gbm(Sift_train)
baseline.time = baseline.result[[4]]
baseline.time
baseline.result[[4]]
class(baseline.result)
baseline.time = baseline.result[[1]]
baseline.result[[1]]
baseline.result[[2]]
baseline.result[[3]]
load("../output/baseline.result.Rdata")
baseline.result
train_gbm(Sift_train[1,])
Sift_train[1,]
train_gbm(Sift_train[1:2,])
??gbm.fit
summary(baseline.result)
baseline.result$fit[[2]]
baseline.result$fit[[1]]
baseline.result$fit[[3]]
baseline.time = baseline.result$fit[[4]]
baseline.result$fit[[4]]
baseline.result$fit[[5]]
save(baseline.result,file = "../output/baseline.result.Rdata")
load("../output/baseline.result.Rdata")
best.iter <- gbm.perf(baseline.result,method='cv')
best.iter <- gbm.perf(baseline.result$fit,method='cv')
best.iter <- gbm.perf(baseline.result$fit)
baseline.result[[3]]
baseline.time = baseline.result$fit[[2]]
baseline.time
baseline.time = baseline.result[[2]]
baseline.time
baseline.result[[2]]
baseline.time
baseline.accuracy = 1 - baseline.result$fit[[3]]
print(paste0("The accuracy rate of baseline model is ", baseline.accuracy))
load("../output/baseline.result.Rdata")
baseline.time = baseline.result[[4]]
baseline.time
baseline.accuracy = mean(1 - baseline.result[[3]])
print(paste0("The accuracy rate of baseline model is ", baseline.accuracy))
baseline.result[[4]]
baseline.result
load("C:/Users/wenyuan/Documents/Fall2017-project3-grp4/output/baseline.result.Rdata")
library(caret)
fitControl <- trainControl(method = "cv", number = 5,returnResamp = "all")
fitControl
model2 <- train(label~., data=Sift_train,method='gbm',distribution='binomial',trControl = fitControl,verbose=F,tuneGrid = data.frame(.n.trees=best.iter,.shrinkage=0.01,.interaction.depth=1))
model2
model2 <- train(label~., data=Sift_train,method='gbm',distribution='binomial',trControl = fitControl,verbose=F,tuneGrid = data.frame(.n.trees=10,.shrinkage=0.01,.interaction.depth=1))
model2
model2 <- train(label~., data=Sift_train,method='gbm',distribution='binomial',trControl = fitControl,verbose=F,tuneGrid = data.frame(.n.trees=10,.shrinkage=0.01,.interaction.depth=1,n.minobsinnode=30))
model2
tuneGrid = data.frame(n.trees=10,.shrinkage=0.01,.interaction.depth=1,n.minobsinnode=30)
tuneGrid
model2 <- train(label~., data=Sift_train,method='gbm',distribution='binomial',trControl = fitControl,verbose=F,tuneGrid = data.frame(n.trees=10,shrinkage=0.01,interaction.depth=1,n.minobsinnode=30))
model2 <- train(label~., data=Sift_train,method='gbm',distribution='multinomial',trControl = fitControl,verbose=F,tuneGrid = data.frame(n.trees=10,shrinkage=0.01,interaction.depth=1,n.minobsinnode=30))
model2
baseline.result
fitControl <- trainControl(method = "cv", number = 2,returnResamp = "all")
fitControl
fitControl <- trainControl(method = "cv", number = 2,returnResamp = "all")
model2 <- train(label~., data=Sift_train,method='gbm',distribution='multinomial',trControl = fitControl,verbose=F,tuneGrid = data.frame(n.trees=1:10,shrinkage=0.1,interaction.depth=1:4,n.minobsinnode=20))
model2
model2 <- train(label~., data=Sift_train,method='gbm',distribution='multinomial',trControl = fitControl,verbose=F,tuneGrid = data.frame(n.trees=1:10,shrinkage=rep(0.1,10),interaction.depth=1:10,n.minobsinnode=rep(20,10)))
model2
df2 = train_test_split("sift")
df2 = train_test_split("lbp")
expand.grid(C = c(0.5,1,2))
svmGrid = expand.grid(C = c(0.5,1,2))
fitControl = trainControl(method = 'cv', number = 2)
train_svm = function(dat_train){
###  dat_train: processed features from images also contains label
library(e1071)
fitControl = trainControl(method = 'cv', number = 2)
svmGrid = expand.grid(C = c(0.5,1,2))
start_time_svm = Sys.time() # Model Start Time
svm.fit = train(label~.,
data = dat_train,
method = "svmLinear",
preProc = c('center', 'scale'),
tuneGrid = svmGrid,
trControl = fitControl)
end_time_svm = Sys.time() # Model End time
svm_time = end_time_svm - start_time_svm #Total Running Time
return(list(fit = svm.fit, time = svm_time))
}
model3 <- train_svm(Sift_train)
library(randomForest)
library(nnet)
library(e1071)
library(e1071)
library(OpenImageR)
??HOG
library(caTools)
library(EBImage)
library(pbapply)
width =64, height = 64,ratio = 0.9, is_test =T
width =64
height = 64
ratio = 0.9
is_test =T
img_dir="../data/test_set/images"
list.files(path=img_dir, pattern = ".*.jpg")
img_dir
list.files(path=img_dir, pattern = ".*.jpg")
images_names  = list.files(path=img_dir, pattern = ".*.jpg")
images_names  = list.files(path=img_dir, pattern = ".jpg")
images_names  = list.files(path=img_dir, pattern = "jpg")
print(paste("Start processing", length(images_names), "images"))
