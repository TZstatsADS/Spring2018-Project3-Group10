fit$x   <- fit$x[!(is.na(fit$y))]
fitted_y <- rep(NA,10)
for (k in 1:10){
index <- which.min(abs(fit$x - test_x[k]))
fitted_y[k] <- fit$y[index]
}
rcv_1[i] <- sum((fitted_y - test_y)^2)/10
rcv_1
rcv[j] <- sum(rcv_1)/5
rcv <- rep(NA,10)
rcv[j] <- sum(rcv_1)/5
rcv[j]
h <- seq(from = 0.05,to = 0.5,by = 0.05)
k <- 5
nums <- rep(1:k, each = length(x)/k)
fold <- sample(nums)
rcv <- rep(NA,10)
for (j in 1:10){
rcv_1 <- rep(NA,5)
for (i in 1:5) {
test_x  <- x[fold == i]
test_y  <- y[fold == i]
train_x <- x[fold != i]
train_y <- y[fold != i]
fit     <- locpoly(train_x,train_y,degree = 1,bandwidth = h[j],gridsize = 1001L)
fit$y   <- fit$y[!(is.na(fit$y))]
fit$x   <- fit$x[!(is.na(fit$y))]
fitted_y <- rep(NA,10)
for (k in 1:10){
index <- which.min(abs(fit$x - test_x[k]))
fitted_y[k] <- fit$y[index]
}
rcv_1[i] <- sum((fitted_y - test_y)^2)/10
}
rcv[j] <- sum(rcv_1)/5
}
rcv
h[which.min(rcv)]
which.min(rcv)
fit_best <- locpoly(x,y,degree = 1,bandwidth = h_best)
h_best <- h[which.min(rcv)]
fit_best <- locpoly(x,y,degree = 1,bandwidth = h_best)
plot(x,y)
lines(fit_best)
install.packages("jpeg")
getwd()
readJPEG("pic.jpg")
library(jpeg)
readJPEG("pic.jpg")
pic <- readJPEG("pic.jpg")
nrow(pic)
help(ksmooth)
#generate data, 2 models with 2 exp dist
gendata <- function(n1, n2){
modeldata <- list()
modeldata$m1 <- rexp(n1, 0.5)
modeldata$m2 <- rexp(n2, 1)
return(modeldata)
}
# simulate to get the expectation
phiR <- function(DataInR){
w <- 0
m1resample <- sample(DataInR$m1, 19, replace = TRUE)
m2resample <- sample(DataInR$m2, 19, replace = TRUE)
x <- m2resample - m1resample
for (i in 1:19){
w = max(w + x[i], 0)
}
return(as.numeric(w > 2))
}
#B >= 2
#First exp
alg4 <- function(OriData, s, B, R){
n <- lapply(OriData, length)
phimat <- matrix(nrow = B, ncol = R)
N1mat <- matrix(nrow = B, ncol = n$m1)
N2mat <- matrix(nrow = B, ncol = n$m2)
for (i in 1:B){
m1bootstrap <- sample(OriData$m1, s$m1, replace = TRUE)
m2bootstrap <- sample(OriData$m2, s$m2, replace = TRUE)
x <- list(m1 = m1bootstrap, m2 = m2bootstrap)
for (j in 1:R){
phimat[i, j] <- phiR(x)
}
#Compute N_{i,j} - s_i / n_i in the Bth Bootstrap (i, j: element j in model i)
for (k in 1:n$m1){
N1mat[i, k] <- sum(x$m1 == OriData$m1[k]) - s$m1 / n$m1
}
for (l in 1:n$m2){
N2mat[i, l] <- sum(x$m2 == OriData$m2[l]) - s$m2 / n$m2
}
}
phib <- apply(phimat, 1, sum) / R
phibarbar<- sum(phib) / B
vec1 <- phib - rep(phibarbar, B)
vec2 <- t(vec1) %*% N1mat
vec3 <- t(vec1) %*% N2mat
vec4 <- t(vec1 ^ 2) %*% N1mat ^ 2
vec5 <- t(vec1 ^ 2) %*% N2mat ^ 2
V <- sum(vec1 ^ 2) / (B - 1)
sigmasqIJ <- (sum(vec2 ^ 2) + sum(vec3 ^ 2)) / (B * (B - 1)) - (sum(vec4) + sum(vec5)) / (B * (B - 1))
list1 <- list(s = V / (B * R), i = sigmasqIJ, phi = phibarbar, v = V)
return(list1)
}
#Second exp
alg4_2 <- function(OriData, s, B, R, Rtilde){
n <- lapply(OriData, length)
phimat <- matrix(nrow = B, ncol = R)
N1mat <- matrix(nrow = B, ncol = n$m1)
N2mat <- matrix(nrow = B, ncol = n$m2)
for (i in 1:B){
m1bootstrap <- sample(OriData$m1, s$m1, replace = TRUE)
m2bootstrap <- sample(OriData$m2, s$m2, replace = TRUE)
x <- list(m1 = m1bootstrap, m2 = m2bootstrap)
for (j in 1:R){
phimat[i, j] <- phiR(x)
}
#Compute N_{i,j} - s_i / n_i in the Bth Bootstrap (i, j: element j in model i)
for (k in 1:n$m1){
N1mat[i, k] <- sum(x$m1 == OriData$m1[k]) - s$m1 / n$m1
}
for (l in 1:n$m2){
N2mat[i, l] <- sum(x$m2 == OriData$m2[l]) - s$m2 / n$m2
}
}
phib <- apply(phimat, 1, sum) / R
phibarbar<- sum(phib) / B
vec1 <- phib - rep(phibarbar, B)
vec2 <- t(vec1) %*% N1mat
vec3 <- t(vec1) %*% N2mat
vec4 <- t(vec1 ^ 2) %*% N1mat ^ 2
vec5 <- t(vec1 ^ 2) %*% N2mat ^ 2
V <- sum(vec1 ^ 2) / (B - 1)
sigmasqIJ <- (sum(vec2 ^ 2) + sum(vec3 ^ 2)) / (B * (B - 1)) - (sum(vec4) + sum(vec5)) / (B * (B - 1))
#fix original data as empirical dist, run \tilde{R} times to get average phitildebar
phitilde <- 0
for (m in 1:Rtilde){
phitilde <- phitilde + phiR(OriData)
}
phitildebar <- phitilde / Rtilde
list1 <- list(s = V / Rtilde , i = sigmasqIJ, phi = phitildebar, v = V)
return(list1)
}
#Third exp
alg4_3 <- function(OriData, s, B, R, Rtilde){
n <- lapply(OriData, length)
phimat <- matrix(nrow = B, ncol = R)
N1mat <- matrix(nrow = B, ncol = n$m1)
N2mat <- matrix(nrow = B, ncol = n$m2)
for (i in 1:B){
m1bootstrap <- sample(OriData$m1, s$m1, replace = TRUE)
m2bootstrap <- sample(OriData$m2, s$m2, replace = TRUE)
x <- list(m1 = m1bootstrap, m2 = m2bootstrap)
for (j in 1:R){
phimat[i, j] <- phiR(x)
}
#Compute N_{i,j} - s_i / n_i in the Bth Bootstrap (i, j: element j in model i)
for (k in 1:n$m1){
N1mat[i, k] <- sum(x$m1 == OriData$m1[k]) - s$m1 / n$m1
}
for (l in 1:n$m2){
N2mat[i, l] <- sum(x$m2 == OriData$m2[l]) - s$m2 / n$m2
}
}
phib <- apply(phimat, 1, sum) / R
phibarbar<- sum(phib) / B
vec1 <- phib - rep(phibarbar, B)
vec2 <- t(vec1) %*% N1mat
vec3 <- t(vec1) %*% N2mat
vec4 <- t(vec1 ^ 2) %*% N1mat ^ 2
vec5 <- t(vec1 ^ 2) %*% N2mat ^ 2
sigmasqIJ <- (sum(vec2 ^ 2) + sum(vec3 ^ 2)) / (B * (B - 1)) - (sum(vec4) + sum(vec5)) / (B * (B - 1))
#fix original data as empirical dist, run \tilde{R} times to get average phitildebar
phitilde <- rep(0, Rtilde)
for (m in 1:Rtilde){
phitilde[m] <- phiR(OriData)
}
phitildebar <- sum(phitilde) / Rtilde
V <- 1 / 2 * sum(vec1 ^ 2) / (B - 1) + var(phitilde) / 2
list1 <- list(s = V / Rtilde , i = sigmasqIJ, phi = phitildebar, v = V)
return(list1)
}
ExpOnAlg4_1 <- function(n1, n2, alpha, s, B, R, Re){
#coverage for those sigma_i >=0, coverage2 for those sigma_i < 0.
#Similar for CIlength and CIlength2; sumV and sumV2; simvar and simvar2
coverage <- 0
coverage2 <- 0
CIlength <- numeric()
CIlength2 <- numeric()
sumV <- 0
sumV2 <- 0
inputvar <- numeric()
simvar <- 0
simvar2 <- 0
t <- 0
#main body
for (times in 1:Re){
x <- gendata(n1, n2)
list1 <- alg4(x, s, B, R)
if (list1$i >= 0){
sigma <- list1$s + list1$i
coverage <- coverage + (abs(0.182 - list1$phi) < (qnorm(1 - alpha / 2) * sqrt(sigma)))
CIlength[times] <- 2 * qnorm(1 - alpha / 2) * sqrt(sigma)
inputvar[times] <- list1$i
simvar <- simvar + list1$s
sumV <- sumV + list1$v
t <- t + 1
}
else{
sigma <- list1$s
coverage2 <- coverage2 + (abs(0.182 - list1$phi) < (qnorm(1 - alpha / 2) * sqrt(sigma)))
CIlength2[times] <- 2 * qnorm(1 - alpha / 2) * sqrt(sigma)
simvar2 <- simvar2 + list1$s
sumV2 <- sumV2 + list1$v
}
}
#out1: remove those sigma_i < 0
sumofsigmaisq1 <- sum(inputvar, na.rm = TRUE)
out1 <- c(t, coverage / t, mean(CIlength, na.rm = TRUE), sd(CIlength, na.rm = TRUE), sqrt(sumofsigmaisq1 / simvar), sumofsigmaisq1 / t, sd(inputvar, na.rm = TRUE), sumofsigmaisq1 / sumV)
#out2: substitue those sigma_i < 0 with 0
totalCIlength <- c(as.numeric(na.omit(CIlength)), as.numeric(na.omit(CIlength2)))
inputvar[is.na(inputvar)] <- 0
out2 <- c((coverage + coverage2) / Re, mean(totalCIlength), sd(totalCIlength), sqrt(sumofsigmaisq1 / (simvar + simvar2)), sumofsigmaisq1 / Re, sd(inputvar), sumofsigmaisq1 / (sumV + sumV2))
out <- c(out1, NA, out2)
return(out)
}
#outcome
s1 = list(m1 = 30, m2 = 30)
ExpOnAlg4_2 <- function(n1, n2, alpha, s, B, R, Rtilde, Re){
#coverage for those sigma_i >=0, coverage2 for those sigma_i < 0.
#Similar for CIlength and CIlength2; sumV and sumV2; simvar and simvar2
coverage <- 0
coverage2 <- 0
CIlength <- numeric()
CIlength2 <- numeric()
sumV <- 0
sumV2 <- 0
inputvar <- numeric()
simvar <- 0
simvar2 <- 0
t <- 0
#main body
for (times in 1:Re){
x <- gendata(n1, n2)
list1 <- alg4_2(x, s, B, R, Rtilde)
if (list1$i >= 0){
sigma <- list1$s + list1$i
coverage <- coverage + (abs(0.182 - list1$phi) < (qnorm(1 - alpha / 2) * sqrt(sigma)))
CIlength[times] <- 2 * qnorm(1 - alpha / 2) * sqrt(sigma)
inputvar[times] <- list1$i
simvar <- simvar + list1$s
sumV <- sumV + list1$v
t <- t + 1
}
else{
sigma <- list1$s
coverage2 <- coverage2 + (abs(0.182 - list1$phi) < (qnorm(1 - alpha / 2) * sqrt(sigma)))
CIlength2[times] <- 2 * qnorm(1 - alpha / 2) * sqrt(sigma)
simvar2 <- simvar2 + list1$s
sumV2 <- sumV2 + list1$v
}
}
#out1: remove those sigma_i < 0
sumofsigmaisq1 <- sum(inputvar, na.rm = TRUE)
out1 <- c(t, coverage / t, mean(CIlength, na.rm = TRUE), sd(CIlength, na.rm = TRUE), sqrt(sumofsigmaisq1 / simvar), sumofsigmaisq1 / t, sd(inputvar, na.rm = TRUE), sumofsigmaisq1 / sumV)
#out2: substitue those sigma_i < 0 with 0
totalCIlength <- c(as.numeric(na.omit(CIlength)), as.numeric(na.omit(CIlength2)))
inputvar[is.na(inputvar)] <- 0
out2 <- c((coverage + coverage2) / Re, mean(totalCIlength), sd(totalCIlength), sqrt(sumofsigmaisq1 / (simvar + simvar2)), sumofsigmaisq1 / Re, sd(inputvar), sumofsigmaisq1 / (sumV + sumV2))
out <- c(out1, NA, out2)
return(out)
}
ExpOnAlg4_3 <- function(n1, n2, alpha, s, B, R, Rtilde, Re){
#coverage for those sigma_i >=0, coverage2 for those sigma_i < 0.
#Similar for CIlength and CIlength2; sumV and sumV2; simvar and simvar2
coverage <- 0
coverage2 <- 0
CIlength <- numeric()
CIlength2 <- numeric()
sumV <- 0
sumV2 <- 0
inputvar <- numeric()
simvar <- 0
simvar2 <- 0
t <- 0
#main body
for (times in 1:Re){
x <- gendata(n1, n2)
list1 <- alg4_3(x, s, B, R, Rtilde)
if (list1$i >= 0){
sigma <- list1$s + list1$i
coverage <- coverage + (abs(0.182 - list1$phi) < (qnorm(1 - alpha / 2) * sqrt(sigma)))
CIlength[times] <- 2 * qnorm(1 - alpha / 2) * sqrt(sigma)
inputvar[times] <- list1$i
simvar <- simvar + list1$s
sumV <- sumV + list1$v
t <- t + 1
}
else{
sigma <- list1$s
coverage2 <- coverage2 + (abs(0.182 - list1$phi) < (qnorm(1 - alpha / 2) * sqrt(sigma)))
CIlength2[times] <- 2 * qnorm(1 - alpha / 2) * sqrt(sigma)
simvar2 <- simvar2 + list1$s
sumV2 <- sumV2 + list1$v
}
}
#out1: remove those sigma_i < 0
sumofsigmaisq1 <- sum(inputvar, na.rm = TRUE)
out1 <- c(t, coverage / t, mean(CIlength, na.rm = TRUE), sd(CIlength, na.rm = TRUE), sqrt(sumofsigmaisq1 / simvar), sumofsigmaisq1 / t, sd(inputvar, na.rm = TRUE), sumofsigmaisq1 / sumV)
#out2: substitue those sigma_i < 0 with 0
totalCIlength <- c(as.numeric(na.omit(CIlength)), as.numeric(na.omit(CIlength2)))
inputvar[is.na(inputvar)] <- 0
out2 <- c((coverage + coverage2) / Re, mean(totalCIlength), sd(totalCIlength), sqrt(sumofsigmaisq1 / (simvar + simvar2)), sumofsigmaisq1 / Re, sd(inputvar), sumofsigmaisq1 / (sumV + sumV2))
out <- c(out1, NA, out2)
return(out)
}
table3 <- matrix(nrow = 5, ncol = 16)
colnames(table3) <- c("t", "Coverage", "mean CI length", "std. CI Length", "sqrt(sigmaIsq/sigmaSsq)", "mean sigmaIsq", "std sigmaIsq", "sigmaIsq/V", "seperate col", "Coverage", "mean CI length", "std. CI Length", "sqrt(sigmaIsq/sigmaSsq)", "mean sigmaIsq", "std sigmaIsq", "sigmaIsq/V")
table3[1,] <- ExpOnAlg4_2(60, 30, 0.05, s1, 1000, 1, 100, 1000)
table3[2,] <- ExpOnAlg4_2(200, 100, 0.05, s1, 1000, 1, 100, 1000)
table3[3,] <- ExpOnAlg4_2(600, 300, 0.05, s1, 2000, 1, 100, 1000)
write.csv(table3, "table3.csv")
## Budget N varies, to choose the optimal B, R, theta as shown in P12 and P13, Rtilde = 100
table4 <- matrix(nrow = 5, ncol = 19)
colnames(table4) <- c("t", "Coverage", "mean CI length", "std. CI Length", "sqrt(sigmaIsq/sigmaSsq)", "mean sigmaIsq", "std sigmaIsq", "sigmaIsq/V", "seperate col", "Coverage", "mean CI length", "std. CI Length", "sqrt(sigmaIsq/sigmaSsq)", "mean sigmaIsq", "std sigmaIsq", "sigmaIsq/V", "theta", "s1", "s2")
table4[1,] <- thetaselection2(60, 30, 0.05, 1000, 1, 100, 1000)
table4[2,] <- thetaselection2(200, 100, 0.05, 1000, 1, 100, 1000)
table4[3,] <- thetaselection2(600, 300, 0.05, 2000, 1, 100, 1000)
write.csv(table4, "table4.csv")
## To reproduce Table1-like on P45 Rtilde = 200
## B = {1000, 1000, 2000, 4000, 6000}, R = 1, s = (30, 30)
table5 <- matrix(nrow = 5, ncol = 16)
colnames(table5) <- c("t", "Coverage", "mean CI length", "std. CI Length", "sqrt(sigmaIsq/sigmaSsq)", "mean sigmaIsq", "std sigmaIsq", "sigmaIsq/V", "seperate col", "Coverage", "mean CI length", "std. CI Length", "sqrt(sigmaIsq/sigmaSsq)", "mean sigmaIsq", "std sigmaIsq", "sigmaIsq/V")
table5[1,] <- ExpOnAlg4_2(60, 30, 0.05, s1, 1000, 1, 200, 1000)
table5[2,] <- ExpOnAlg4_2(200, 100, 0.05, s1, 1000, 1, 200, 1000)
## Budget N varies, to choose the optimal B, R, theta as shown in P12 and P13, Rtilde = 100
thetaselection2 <- function(n1, n2, alpha, B, R, Rtilde, Re){
n = (n1 + n2) / 2
theta = min(sqrt(B), n ^ (3 / 4)) * n ^ (-5 / 4)
s1 <- ceiling(n1 * theta)
s2 <- ceiling(n2 * theta)
s <- list(m1 = s1, m2 = s2)
out <- c(ExpOnAlg4_2(n1, n2, alpha, s, B, R, Rtilde, Re), theta, s1, s2)
return(out)
}
## Budget N varies, to choose the optimal B, R, theta as shown in P12 and P13, Rtilde = 100
thetaselection3 <- function(n1, n2, alpha, B, R, Rtilde, Re){
n = (n1 + n2) / 2
theta = min(sqrt(B), n ^ (3 / 4)) * n ^ (-5 / 4)
s1 <- ceiling(n1 * theta)
s2 <- ceiling(n2 * theta)
s <- list(m1 = s1, m2 = s2)
out <- c(ExpOnAlg4_3(n1, n2, alpha, s, B, R, Rtilde, Re), theta, s1, s2)
return(out)
}
table4 <- matrix(nrow = 5, ncol = 19)
colnames(table4) <- c("t", "Coverage", "mean CI length", "std. CI Length", "sqrt(sigmaIsq/sigmaSsq)", "mean sigmaIsq", "std sigmaIsq", "sigmaIsq/V", "seperate col", "Coverage", "mean CI length", "std. CI Length", "sqrt(sigmaIsq/sigmaSsq)", "mean sigmaIsq", "std sigmaIsq", "sigmaIsq/V", "theta", "s1", "s2")
table4[1,] <- thetaselection2(60, 30, 0.05, 1000, 1, 100, 1000)
table4[2,] <- thetaselection2(200, 100, 0.05, 1000, 1, 100, 1000)
table4[3,] <- thetaselection2(600, 300, 0.05, 2000, 1, 100, 1000)
write.csv(table4, "table4.csv")
## To reproduce Table1-like on P45 Rtilde = 200
## B = {1000, 1000, 2000, 4000, 6000}, R = 1, s = (30, 30)
table5 <- matrix(nrow = 5, ncol = 16)
colnames(table5) <- c("t", "Coverage", "mean CI length", "std. CI Length", "sqrt(sigmaIsq/sigmaSsq)", "mean sigmaIsq", "std sigmaIsq", "sigmaIsq/V", "seperate col", "Coverage", "mean CI length", "std. CI Length", "sqrt(sigmaIsq/sigmaSsq)", "mean sigmaIsq", "std sigmaIsq", "sigmaIsq/V")
table5[1,] <- ExpOnAlg4_2(60, 30, 0.05, s1, 1000, 1, 200, 1000)
table5[2,] <- ExpOnAlg4_2(200, 100, 0.05, s1, 1000, 1, 200, 1000)
table5[3,] <- ExpOnAlg4_2(600, 300, 0.05, s1, 2000, 1, 200, 1000)
write.csv(table5, "table5.csv")
## Budget N varies, to choose the optimal B, R, theta as shown in P12 and P13, Rtilde = 100
table6 <- matrix(nrow = 5, ncol = 19)
colnames(table6) <- c("t", "Coverage", "mean CI length", "std. CI Length", "sqrt(sigmaIsq/sigmaSsq)", "mean sigmaIsq", "std sigmaIsq", "sigmaIsq/V", "seperate col", "Coverage", "mean CI length", "std. CI Length", "sqrt(sigmaIsq/sigmaSsq)", "mean sigmaIsq", "std sigmaIsq", "sigmaIsq/V", "theta", "s1", "s2")
table6[1,] <- thetaselection2(60, 30, 0.05, 1000, 1, 200, 1000)
table6[2,] <- thetaselection2(200, 100, 0.05, 1000, 1, 200, 1000)
table6[3,] <- thetaselection2(600, 300, 0.05, 2000, 1, 200, 1000)
write.csv(table6, "table6.csv")
table7 <- matrix(nrow = 5, ncol = 16)
colnames(table7) <- c("t", "Coverage", "mean CI length", "std. CI Length", "sqrt(sigmaIsq/sigmaSsq)", "mean sigmaIsq", "std sigmaIsq", "sigmaIsq/V", "seperate col", "Coverage", "mean CI length", "std. CI Length", "sqrt(sigmaIsq/sigmaSsq)", "mean sigmaIsq", "std sigmaIsq", "sigmaIsq/V")
table7[1,] <- ExpOnAlg4_3(60, 30, 0.05, s1, 1000, 1, 100, 1000)
table7[2,] <- ExpOnAlg4_3(200, 100, 0.05, s1, 1000, 1, 100, 1000)
table7[3,] <- ExpOnAlg4_3(600, 300, 0.05, s1, 2000, 1, 100, 1000)
write.csv(table7, "table7.csv")
## Budget N varies, to choose the optimal B, R, theta as shown in P12 and P13, Rtilde = 100
table8 <- matrix(nrow = 5, ncol = 19)
colnames(table8) <- c("t", "Coverage", "mean CI length", "std. CI Length", "sqrt(sigmaIsq/sigmaSsq)", "mean sigmaIsq", "std sigmaIsq", "sigmaIsq/V", "seperate col", "Coverage", "mean CI length", "std. CI Length", "sqrt(sigmaIsq/sigmaSsq)", "mean sigmaIsq", "std sigmaIsq", "sigmaIsq/V", "theta", "s1", "s2")
table8[1,] <- thetaselection3(60, 30, 0.05, 1000, 1, 100, 1000)
table8[2,] <- thetaselection3(200, 100, 0.05, 1000, 1, 100, 1000)
table8[3,] <- thetaselection3(600, 300, 0.05, 2000, 1, 100, 1000)
setwd("~/GitHub/Spring2018-Project3-spring2018-project3-group10/doc")
load("~/GitHub/Spring2018-Project3-spring2018-project3-group10/output/err_cv_HOG_svm.RData")
err_cv
err_cv_svm <- data.frame(err_cv[,1])
err_cv_svm
err_cv_svm <- data.frame(t(err_cv[,1])
err_cv_svm <- data.frame(t(err_cv[,1]))
err_cv_svm
err_cv_svm <- data.frame(HOG = t(err_cv[,1]))
err_cv_svm
hog_cv <- err_cv
hog_cv <- err_cv[,1]
load("~/GitHub/Spring2018-Project3-spring2018-project3-group10/output/err_cv_LBP_svm.RData")
lbp_cv <- err_cv[,1]
load("~/GitHub/Spring2018-Project3-spring2018-project3-group10/output/err_cv_sift_svm.RData")
sift_cv <- err_cv[,1]
err_cv_svm <- rbind(hog_cv,lbp_cv,sift_cv)
err_cv_svm
class(err_cv_svm)
err_cv_svm <- as.data.frame(err_cv_svm)
rownames(err_cv_svm) <- c("HOG","LBP","SIFT")
colnames(err_cv_svm) <- c("gamma = 0.01","0.03","0.05","0.07","0.09")
err_cv_svm
colnames(err_cv_svm) <- c("gamma = 0.01","gamma = 0.03","gamma = 0.05","gamma = 0.07","gamma = 0.09")
err_cv_svm
load("~/GitHub/Spring2018-Project3-spring2018-project3-group10/output/err_cv_HOG_svm.RData")
hog_cv <- err_cv[,1]
load("~/GitHub/Spring2018-Project3-spring2018-project3-group10/output/err_cv_LBP_svm.RData")
lbp_cv <- err_cv[,1]
load("~/GitHub/Spring2018-Project3-spring2018-project3-group10/output/err_cv_sift_svm.RData")
sift_cv <- err_cv[,1]
err_cv_svm <- rbind(hog_cv,lbp_cv,sift_cv)
err_cv_svm <- as.data.frame(err_cv_svm)
rownames(err_cv_svm) <- c("HOG","LBP","SIFT")
colnames(err_cv_svm) <- c("gamma = 0.01","gamma = 0.03","gamma = 0.05","gamma = 0.07","gamma = 0.09")
print(err_cv_svm)
setwd("~/GitHub/Spring2018-Project3-spring2018-project3-group10/doc")
getwd()
# read train dataset
dat_train <- read.csv('../data/SIFT_train.csv', header = F)
label_train <- read.csv('../data/label_train.csv')
dat_train <- dat_train[, -1]
label_train <- label_train[,3]
#
source("../lib/train.R")
source("../lib/test.R")
source("../lib/cross_validation.R")
# which model to perform cross validation
run.cv = T
cv.xgboost = T
K = 5
xgboost_values <- seq(0.1, 0.5, by = 0.1) # eta for xgboost
xgboost_labels = paste("XGBoost with eta =", xgboost_values)
#
if(run.cv){
if(cv.xgboost){
err_cv <- array(dim=c(length(xgboost_values), 2))
for(k in 1:length(xgboost_values)){
cat("k=", k, "\n")
err_cv[k,] <- cv.function(as.data.frame(dat_train), label_train, xgboost_values[k], K, cv.xgboost = T)
}
}
save(err_cv, file="../output/err_cv_sift_xg.RData")
}
load("~/GitHub/Spring2018-Project3-spring2018-project3-group10/output/err_cv_hog_xg.RData")
err_cv
err_cv
View(err_cv_svm)
cv.error
array(dim=c(length(xgboost_values), 2))
label_train
#
k=1
err_cv[k,] <- cv.function(as.data.frame(dat_train), label_train, xgboost_values[k], K, cv.xgboost = T)
err_cv[k,] <- cv.function(as.data.frame(dat_train), label_train, xgboost_values[k], K, cv.xgboost = T)
err_cv[k,]
err_cv
err_cv[k,] <- cv.function(as.data.frame(dat_train), label_train, xgboost_values[k], K, cv.xgboost = T)
err_cv
err_cv[k,]
k
xgboost_values[k]
err_cv
k=1
xgboost_values
setwd("~/GitHub/Spring2018-Project3-spring2018-project3-group10/doc")
getwd()
# read train dataset
dat_train <- read.csv('../data/SIFT_train.csv', header = F)
label_train <- read.csv('../data/label_train.csv')
dat_train <- dat_train[, -1]
label_train <- label_train[,3]
#
source("../lib/train.R")
source("../lib/test.R")
source("../lib/cross_validation.R")
# which model to perform cross validation
run.cv = T
cv.xgboost = T
K = 5
xgboost_values <- seq(0.1, 0.5, by = 0.1) # eta for xgboost
xgboost_labels = paste("XGBoost with eta =", xgboost_values)
k=1
err_cv <- array(dim=c(length(xgboost_values), 2))
err_cv
err_cv[k,] <- cv.function(as.data.frame(dat_train), label_train, xgboost_values[k], K, cv.xgboost = T)
err_cv
k=2
err_cv[k,]
err_cv[k,] <- cv.function(as.data.frame(dat_train), label_train, xgboost_values[k], K, cv.xgboost = T)
err_cv
#
k=3
err_cv[k,] <- cv.function(as.data.frame(dat_train), label_train, xgboost_values[k], K, cv.xgboost = T)
err_cv
k=4
err_cv[k,] <- cv.function(as.data.frame(dat_train), label_train, xgboost_values[k], K, cv.xgboost = T)
err_cv
#
k=5
err_cv[k,] <- cv.function(as.data.frame(dat_train), label_train, xgboost_values[k], K, cv.xgboost = T)
err_cv
save(err_cv, file="../output/err_cv_sift_xg.RData")
err_cv
